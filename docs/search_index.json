[["index.html", "Course on Mixed-effects Models Course information Desirable background knowledge Overview of dates Literature", " Course on Mixed-effects Models Nora Wickelmaier 2024-10-14 Course information This is an online book accompanying a course on mixed-effects models taught to PhD students at the Leibniz-Institut für Wissensmedien (IWM) in Tübingen. So far, this is work in progress and very rudimentary! Desirable background knowledge Alle examples in this course are worked out in R. Introductory knowledge in R is therefore a prerequisite. If you want to freshen up your R knowledge a bit, you can go through the exercises provided here: https://nwickel.github.io/R_intro/. Apart from this, I will assume that you have some kind of workflow how to use R with a text editor (e.g., Vim) or an IDE (e.g., RStudio). It is further assumed that you have attended at least one introductory statistics course (level “Statisik I” and “Statistik II” usually taught in psychology curricula at German universities). That means you should be familiar with concepts like random variables, statstical distributions like the normal distribution, t distribution, Binomial distribution, etc., and hypothesis testing. Some background in regression analysis is helpful, but we will cover the basics of this in this course. If you feel like these concepts could be a bit more “present” in your head, you can go through the first Section in the online book by Vasishth et al. (2022). There will be time to ask questions about all of these concepts in this session, but we will not have time to got through all the concepts together. Hopefully, these resources will help to get everybody on the same page. If you need more support or materials, just let me know. Overview of dates Date Topic 28.10.2024 Simple and multiple regression 11.11.2024 Generalized linear models 25.11.2024 Pre/post measurements 09.12.2024 Introduction to mixed-effects models 13.01.2025 Longitudinal data I 27.01.2025 Longitudinal data II 10.02.2025 Growth curve models Crossed random effects Gelman and Brown Multilevel models Simulation-based power analysis Power simulation LMM Power simulation GLMM Literature This course is mostly built on the following books and papers: Baayen, Davidson, and Bates (2008) Bates et al. (2015) Gelman, Hill, and Vehtari (2020) Vasishth et al. (2022) Wickelmaier (2022) References "],["simple-and-multiple-regression.html", "Chapter 1 Simple and multiple regression 1.1 Slides 1.2 Example to illustrate assumptions 1.3 Exercises", " Chapter 1 Simple and multiple regression This chapter is meant to give a short introduction to regression analysis. It is mostly meant to reintroduce some basic concepts, introduce notation, and get everybody on the same page. 1.1 Slides Unable to display PDF file. Download instead. 1.2 Example to illustrate assumptions Code data(anscombe) lm1 &lt;- lm(y1 ~ x1, anscombe) lm2 &lt;- lm(y2 ~ x2, anscombe) lm3 &lt;- lm(y3 ~ x3, anscombe) lm4 &lt;- lm(y4 ~ x4, anscombe) # Compare estimates rbind(coef(lm1), coef(lm2), coef(lm3), coef(lm4)) ## (Intercept) x1 ## [1,] 3.000091 0.5000909 ## [2,] 3.000909 0.5000000 ## [3,] 3.002455 0.4997273 ## [4,] 3.001727 0.4999091 Code # Plot data par(mfrow=c(2,2), mai = c(.6, .6, .1, .1), mgp = c(2.4, 1, 0)) plot(y1 ~ x1, anscombe, pch = 16, col = &quot;blue&quot;) abline(lm1, lwd = 2) plot(y2 ~ x2, anscombe, pch = 16, col = &quot;blue&quot;) abline(lm2, lwd = 2) plot(y3 ~ x3, anscombe, pch = 16, col = &quot;blue&quot;) abline(lm3, lwd = 2) plot(y4 ~ x4, anscombe, pch = 16, col = &quot;blue&quot;) abline(lm4, lwd = 2) Code # Look at assumption violations par(mfrow = c(2,2)) plot(lm1) Code plot(lm2) Code plot(lm3) Code plot(lm4) Code # Reshape data frame to long format dat &lt;- reshape(anscombe, direction = &quot;long&quot;, varying = list(paste0(&quot;x&quot;, 1:4), paste0(&quot;y&quot;, 1:4)), timevar = &quot;reg&quot;, v.names = c(&quot;x&quot;, &quot;y&quot;))[, -4] # drop id lattice::xyplot(y ~ x | as.factor(reg), dat, pch=16, type=c(&quot;p&quot;, &quot;r&quot;)) Code lattice::xyplot(y ~ x | as.factor(reg), dat, pch=16, type=c(&quot;p&quot;, &quot;smooth&quot;)) 1.3 Exercises Exercise 1 Simulate a data set based on a simple regression model with \\[\\begin{align*} \\beta_0 &amp; = 0.2\\\\ \\beta_1 &amp; = 0.3\\\\ \\sigma &amp; = 0.5\\\\ x &amp; \\in [1, 20]~\\text{in steps of 1} \\end{align*}\\] What functions in R do we need? Code x &lt;- 1:20 n &lt;- length(x) a &lt;- 0.2 b &lt;- 0.3 sigma &lt;- 0.5 y &lt;- 0.2 + 0.3*x + rnorm(n, sd = sigma) dat &lt;- data.frame(x, y) lm1 &lt;- lm(y ~ x, dat) summary(lm1) mean(resid(lm1)) sd(resid(lm1)) hist(resid(lm1), breaks = 15) Code # plot data plot(y ~ x, dat) abline(lm1) Exercise 2 Simulate data with the parameters from Exercise 1 Do not assume that we have one subject per value for \\(x\\), but more than one subject Simulate data for \\(n = 40\\) and \\(n = 100\\) Hint: Use sample(x, n, replace = TRUE) Re-cover your parameters as done on slide 11 What happens to your standard errors? Code n &lt;- 100 # 40 x0 &lt;- 1:20 x &lt;- sample(x0, n, replace = TRUE) a &lt;- 0.2 b &lt;- 0.3 sigma &lt;- 0.5 y &lt;- 0.2 + 0.3*x + rnorm(n, sd = sigma) dat &lt;- data.frame(x, y) pars &lt;- replicate(2000, { ysim &lt;- 0.2 + 0.3 * x + rnorm(n, sd = sigma) lm1 &lt;- lm(ysim ~ x, data = dat) c(coef(lm1), sigma(lm1)) }) rowMeans(pars) # standard errors apply(pars, 1, sd) hist(pars[1, ]) Code hist(pars[2, ]) Code hist(pars[3, ]) Code plot(y ~ jitter(x), dat) Exercise 3 Create two vectors \\(x\\) and \\(y\\) with 100 observations each and \\(X \\sim N(1,1)\\) and \\(Y \\sim N(2,1)\\). Create a data frame with variables , and . \\(x\\) and \\(y\\) are your score values. Conduct a \\(t\\) test assuming that \\(X\\) and \\(Y\\) are independent having the same variances. Then use the function aov() to compute an analysis of variance for these data. Use then function lm() for a linear regression with predictor group and dependent variable score. Compare your results. Code x &lt;- rnorm(100, mean = 1) y &lt;- rnorm(100, mean = 2) dat &lt;- data.frame(id = 1:200, group = rep(c(&quot;x&quot;,&quot;y&quot;), each = 100), score = c(x, y)) rm(x,y) t1 &lt;- t.test(score ~ group, data = dat, var.equal = TRUE) lm1 &lt;- lm(score ~ group, data = dat) aov1 &lt;- aov(score ~ group, data = dat) (stat &lt;- list( coef = matrix(c(t1$estimate, lm1$coef, aov1$coef), nrow = 2, ncol = 3, dimnames = list(NULL, c(&quot;ttest&quot;, &quot;lm&quot;, &quot;aov&quot;))), statistics = matrix(c(t = t1$statistic^2, Flm = summary(lm1)$fstatistic[1], Faov = unlist(summary(aov1))[7]), nrow = 1, ncol = 3, dimnames = list(NULL, c(&quot;t&quot;,&quot;Flm&quot;,&quot;Faov&quot;)))) ) Exercise 4 The data set cars contains speed and stopping distances of 50 cars Estimate the regression model \\[ dist_i = \\beta_0 + \\beta_1 speed_i + \\varepsilon_i \\] How much variance of the stopping distances is explained by speed? Look at the residuals of the model. Are there any systematic deviances? Now estimate the model \\[ dist_i = \\beta_0 + \\beta_1 speed_i + \\beta_2 speed^2_i + \\varepsilon_i \\] Hint: Use I(speed^2) in the model formula Which model fits the data better? Code data(cars) lm1 &lt;- lm(dist ~ speed, data = cars) summary(lm1) hist(resid(lm1)) Code par(mfrow = c(2,2)) plot(lm1) Code lm2 &lt;- lm(dist ~ speed + I(speed^2), data = cars) anova(lm1, lm2) "],["generalized-linear-models.html", "Chapter 2 Generalized linear models 2.1 Slides 2.2 Exercises", " Chapter 2 Generalized linear models 2.1 Slides Unable to display PDF file. Download instead. 2.2 Exercises Exercise 1 In a psychophysical experiment two LEDs are presented to a subject: a standard with 40 cd/m\\(^2\\) and a comparison with varying intensities The subject is supposed to say which stimulus is brighter; each comparison is presented 40 times x (cd/m\\(^2\\)) 37 38 39 40 41 42 43 y (positiv) 2 3 10 25 34 36 39 Estimate parameters \\(c\\) and \\(a\\) of the logistic psychometric function \\[ p_{pos} = \\frac{1}{1 + \\exp(-\\frac{\\displaystyle x - c}{\\displaystyle a})} \\] using `glm()´ with \\(logit(p_{pos}) = \\beta_0 + \\beta_1x\\) where \\(a = 1/\\beta_1\\) and \\(c = -\\beta_0/\\beta_1\\). Calculate the intensity \\(x\\) for which \\(p_{pos} = 0.5\\) (Point of Subjective Equality, PSE) Code dat &lt;- data.frame(x = 37:43, y = c(2, 3, 10, 25, 34, 36, 39), n = 40) glm1 &lt;- glm(cbind(y, n - y) ~ x, family = binomial, data = dat) a &lt;- 1 / coef(glm1)[2] c &lt;- -coef(glm1)[1] / coef(glm1)[2] Exercise 2 Create a plot for the probability to give a positive answer depending on the intensity of the comparison Use predict() to obtain the predicted values and add the logistic psychometric function to the plot Use abline() to add parameter \\(c\\) to the plot Use a likelihood ratio test to assess how well the model fits the data Is there reason to assume that there is any overdispersion? Code newx &lt;- seq(37, 43, .1) pre &lt;- predict(glm1, newdata = data.frame(x = newx), type = &quot;response&quot;) # Plot predictions with PSE plot(y/n ~ x, data = dat, pch = 16, ylab = &quot;Probability to say brighter&quot;) lines(pre ~ newx, data = dat) abline(v = c, h = .5, lty = 3) text(39, .8, paste(&quot;PSE =&quot;, round(c, 2))) Code # Goodness-of-fit test glms &lt;- glm(cbind(y, n-y) ~ factor(x), family = binomial, data = dat) anova(glm1, glms, test = &quot;Chisq&quot;) # Overdispersion summary(glm(cbind(y, n - y) ~ x, family = quasibinomial, data = dat)) Exercise 3 Fit a regression model to the Affairs data set from the AER package in R The variable affairs is the number of extramarital affairs in the past year and is our response variable Include the variables gender, age, yearsmarried, children, religiousness, education and rating as predictors religiousness ranges from 1 (anti) to 5 (very) and rating is a self rating of the marriage, ranging from 1 (very unhappy) to 5 (very happy) Assess the Goodness-of-fit using the deviance Assess overdispersion and decide if a model with an extra dispersion parameter might be indicated Compare the confidence intervals for the estimated parameters for both models Code # Load data set data(Affairs, package = &quot;AER&quot;) Affairs$rating &lt;- factor(Affairs$rating, levels = 1:5) ## Fit poisson model pois1 &lt;- glm(affairs ~ gender + age + yearsmarried + children + education + rating, family = poisson, data = Affairs) summary(pois1) # Goodness-of-fit 1 - pchisq(pois1$deviance, df = pois1$df.residual) ## Model with dispersion parameter pois2 &lt;- glm(affairs ~ gender + age + yearsmarried + children + education + rating, family = quasipoisson, data = Affairs) summary(pois2) ## Compare CIs confint(pois1) confint(pois2) Visualize model predictions Code ## Plot predictions for &quot;average&quot; females newdat &lt;- expand.grid(yearsmarried = seq(0, 15, 1), rating = factor(1:5)) newdat$gender &lt;- &quot;female&quot; newdat$age &lt;- mean(Affairs$age) newdat$children &lt;- &quot;yes&quot; newdat$religiousness &lt;- mean(Affairs$religiousness) newdat$education &lt;- mean(Affairs$education) newdat$pre &lt;- predict(pois2, newdata = newdat, type = &quot;response&quot;) colors &lt;- c(&quot;#78004B&quot;, &quot;#3CB4DC&quot;, &quot;#91C86E&quot;, &quot;#FF6900&quot;, &quot;#434F4F&quot;) plot(pre ~ yearsmarried, newdat, type = &quot;n&quot;, main = &quot;&#39;Average&#39; Females&quot;) for (i in 1:5) { lines(pre ~ yearsmarried, newdat[newdat$rating == i, ], col = colors[i]) } legend(&quot;topleft&quot;, c(&quot;very unhappy&quot;, &quot;somewhat unhappy&quot;, &quot;average&quot;, &quot;happier than average&quot;, &quot;very happy&quot;), col = colors, lty = 1, bty = &quot;n&quot;) "],["prepost-measurements.html", "Chapter 3 Pre/post measurements 3.1 Slides 3.2 Exercises", " Chapter 3 Pre/post measurements 3.1 Slides Unable to display PDF file. Download instead. 3.2 Exercises Code # TODO: Add exercises "],["longitudinal-data.html", "Chapter 4 Longitudinal data 4.1 Slides 4.2 Exercises", " Chapter 4 Longitudinal data 4.1 Slides TODO 4.2 Exercises Code # TODO: Add exercises "],["repeated-measurements.html", "Chapter 5 Repeated measurements 5.1 Slides 5.2 Exercises", " Chapter 5 Repeated measurements 5.1 Slides TODO 5.2 Exercises Code # TODO: Add exercises "],["data-simulation-for-linear-mixed-effects-models.html", "Chapter 6 Data simulation for linear mixed-effects models 6.1 Slides 6.2 Exercises", " Chapter 6 Data simulation for linear mixed-effects models 6.1 Slides TODO 6.2 Exercises Code # TODO: Add exercises "],["introduction-to-power.html", "Chapter 7 Introduction to power 7.1 Slides 7.2 Exercises", " Chapter 7 Introduction to power 7.1 Slides TODO 7.2 Exercises Code # TODO: Add exercises "],["power-simulation-for-glmm.html", "Chapter 8 Power simulation for GLMM 8.1 Slides 8.2 Exercises", " Chapter 8 Power simulation for GLMM 8.1 Slides TODO 8.2 Exercises Code # TODO: Add exercises "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
