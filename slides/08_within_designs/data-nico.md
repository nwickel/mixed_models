# Methods

## Study Design

This study employed a 5 (Context: medical, legal, financial, psychological,
educational) × 2 (Stakes: high vs. low) × 2 (Interaction Partner: AIES vs.
human) mixed design. Context served as a between-subjects factor, while both
stakes and interaction partner were manipulated within-subjects. The study was
preregistered on the OSF ([OSF link placeholder]) and a priori power analyses
confirmed sufficient power to detect interaction effects. Specifically, the
power for the predictor 'Context × Partner' was 99.60% (95% CI: 99.21, 99.83),
based on 2,000 simulations using a Type-2 F-test with Satterthwaite degrees of
freedom (alpha = .05, n = 3,592).

## Participants

A total of 898 UK participants ($M_age = 42$, $SD = 14$; 50.6% female; 36% with
a high-school diploma or equivalent, 62% with a Bachelor’s degree or higher)
were recruited via the online platform Prolific. Participants were randomly
assigned to one of the five context conditions, with approximately 180
individuals per group.

## Procedure

Participants first provided informed consent and completed a set of background
measures, including general attitudes toward AI, subjective and objective AI
knowledge, prior AI experience, and general propensity to trust. Subsequently,
they were presented with the introduction to AIES:

"An AI expert system is an artificial intelligence system that can do work
similar to that of human professionals such as lawyers, doctors,
psychotherapists, tax accountants, or teachers. It is a computer program that
uses knowledge and rules to help solve problems in a specific area. It mimics
the expertise of a human expert and can give advice and make decisions based on
the information it has learned. It's like having a digital expert in a
particular field."

However, to make an informed decision about whether to trust AIES—and to
evaluate their perceived risk and trustworthiness—a concise set of additional
descriptive elements was provided. These elements were necessary to control for
the many relevant factors that might otherwise remain unaddressed. The final
list of descriptive elements stated that an AIES

* “is approved by an official governmental assessment procedure;
* guarantees regulatory compliance; ensures ethical behavior;
* guarantees the protection of user privacy (including user data);
* indicates the accuracy and reliability of external data sources;
* is fully transparent about its decision-making procedure;
* provides full transparency about all costs before they occur;
* and informs truthfully about the company that created it and its country of
  origin.”

The survey instruments and descriptive elements were calibrated and validated
during preliminary studies (S1–S5; see Sup for more information). Afterward,
participants were randomly assigned to one of five professional context
conditions and exposed to two matched scenarios (low-stakes and high-stakes),
presented in counterbalanced order. Each scenario asked participants to compare
a human expert and an AIES in that context.

## Measures

Perceived Trustworthiness was measured using the nine-item short version of the
Münster Epistemic Trustworthiness Inventory (METI; [REF]), assessing the
dimensions of expertise, integrity, and benevolence on 7-point bipolar scales
(e.g., incompetent–competent).

Perceived Risk and Trust (willingness to rely) were each assessed using a
single-item 7-point scale ("None at all" to "Maximally")."
 

# Results

Hier noch preliminär und noch nicht abgesegent ein Teil der Analyses und
Results: 
 
## Linear Mixed-Effects Models (LMMs) for Trustworthiness and Risk

To test H1 and H2, we conducted two linear mixed-effects models predicting
perceived trustworthiness and perceived risk, respectively. Fixed effects
included Context (reference: educational), Partner (reference: AIES), Stakes
(reference: high), and their interactions. Random intercepts and slopes for
Partner and Stakes were modeled at the participant level. Full model estimates,
including significance levels and effect sizes, are reported in Table 1.

